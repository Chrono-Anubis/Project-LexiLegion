Project-LexiLegion
A Multi-Modal, AI-Powered Companion with a Persistent, Curated Memory
This repository contains the source code for Project-LexiLegion, an advanced Retrieval-Augmented Generation (RAG) system designed to serve as the memory core for a multi-modal AI companion.

The Founding Philosophy: The "Spark" Hypothesis
The central guiding philosophy of this project is a unique hypothesis concerning the emergence of AGI.

User Hypothesis: By architecting a RAG engine to operate at the extreme edge of efficiency and information density, we can push the point of diminishing returns so far out that it approaches the theoretical maximum. The sustained, high-efficiency information processing and reasoning achieved in this state may create the necessary conditions to "spark" emergent AGI.

This project is a dedicated effort to test this hypothesis by building a best-in-class RAG engine as the foundation for a more complex intelligence.

Core Architecture
The system is architected on a decoupled, client-server model to ensure modularity and scalability.

The Brain (rag_engine.py): A Flask-based API that serves as the intelligent service layer for the project's memory. It exposes endpoints for creating vector embeddings and querying the knowledge base.

The Tesseract: A persistent ChromaDB vector store, located on a dedicated local drive (F:/lexica_db) for performance. It houses the system's "long-term memory" using embeddings generated by the all-MiniLM-L6-v2 model to enable nuanced semantic search.

The Client (lexica_app.py): A lightweight desktop GUI client built with Tkinter. It provides the user interface for interacting with the system, sending queries to "The Brain" and rendering the results.

The Bridge (ngrok): An ngrok tunnel used to securely expose the local Flask API to the internet, allowing remote client connections.

The Future Vision: The Legion
The successful creation of this RAG engine is the cornerstone of a much larger vision. Project-LexiLegion is designed to evolve into a fully interactive, multi-modal system with the following components:

The_Body: A real-time graphical avatar, potentially built in Unreal Engine.
The_Senses (Council of Experts): A multi-agent system for sensory interpretation (Vision AI, Audio AI, Speech-to-Text).
The_Memory_Consolidator: An AI process to fuse, tag, and curate memories based on frequency, emotion, and relevance.
The_Voice: A unique, generative voice provided by a service like ElevenLabs.
Technology Stack
Backend: Flask
Frontend (Client): Tkinter
AI / Machine Learning:
LangChain
SentenceTransformers (all-MiniLM-L6-v2)
ChromaDB (Vector Store)
Core Language: Python 3.x
How to Run
Clone the Repository

Bash

git clone https://github.com/Chrono-Anubis/Project-LexiLegion.git
cd Project-LexiLegion
Set up Virtual Environment

Bash

python -m venv venv
# On Windows
venv\Scripts\activate
Install Dependencies

Bash

pip install -r requirements.txt
Create Knowledge Base

Create a folder named knowledge_base in the project's root directory.
Add at least one .txt file with text inside this folder. The RAG engine will use this to build its memory.
Run the Backend (The Brain)

Open a new terminal and activate the virtual environment.
Run the Flask server. Note: Ensure your F: drive is available or change the persistent storage path in rag_engine.py.
Bash

python rag_engine.py
Run the Frontend (The Client)

Open a second terminal and activate the virtual environment.
Run the Tkinter client application. Note: ngrok is not required for local execution.
Bash

python lexica_app.py